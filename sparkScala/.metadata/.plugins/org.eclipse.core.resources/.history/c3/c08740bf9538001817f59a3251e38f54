package main
import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.log4j._
import javax.script.ScriptContext
import org.apache.spark.sql.SparkSession


object SparkSQL {
  def main(args: Array[String]){
    Logger.getLogger("org").setLevel(Level.ERROR);
    
    // Session is used to have dataSet instead of rdd.
    val session = SparkSession.builder().appName("SQL").master("local[*]").getOrCreate(); // in case there is a node failure, it can get the already created session.
    
    
    val sparkContext = session.sparkContext.textFile("../fakefriends.csv");
    
    
  }
  
}